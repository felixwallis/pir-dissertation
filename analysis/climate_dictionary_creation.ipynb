{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Climate Dictionary Creation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook creates a dictionary of climate terms which can be used to filter Hansard and the Congressional Record to create a climate corpus. The notebook uses the IPCC Sixth Assessment Report Glossary as the dictionary's basis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "data_path = 'data/'\n",
    "dist_path = 'dist/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting climate terms and their definitions from the IPCC Sixth Assessment Report Glossary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the text from the IPCC Sixth Assessment Report Glossary PDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "glossary_path = data_path + 'IPCC Sixth Assessment Report Glossary.pdf'\n",
    "doc = fitz.open(glossary_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glossary cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remomving the first and final three pages of the glossary\n",
    "glossary_text = [page.get_text() for page in doc]\n",
    "glossary_text.pop(0)\n",
    "glossary_text = glossary_text[:-3]\n",
    "\n",
    "# Concatenating the glossary text\n",
    "glossary_text_string = ' '.join(glossary_text)\n",
    "\n",
    "# Removing superfluous text\n",
    "pattern = r\"(Approval Session|Glossary|IPCC SR1\\.5|Do Not Cite, Quote or Distribute|Total pages: \\d+|See [A-Za-z]+\\.|1-\\d+)\"\n",
    "cleaned_glossary_text = re.sub(pattern, '', glossary_text_string).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing the cleaned glossary text to a file\n",
    "with open(dist_path + 'glossary.txt', 'w') as f:\n",
    "    f.write(cleaned_glossary_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a rough dataframe of climate terms and their definitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = re.split(r'\\s\\s\\s\\s\\s+', cleaned_glossary_text)\n",
    "\n",
    "terms = []\n",
    "definitions = []\n",
    "\n",
    "for chunk in chunks:\n",
    "    term = re.split(r'\\s\\s', chunk)[0]\n",
    "    definition = re.split(r'\\s\\s', chunk)[1:]\n",
    "    definition = ' '.join(definition)\n",
    "\n",
    "    terms.append(term)\n",
    "    definitions.append(definition)\n",
    "\n",
    "climate_dictionary = pd.DataFrame({'term': terms, 'definition': definitions})\n",
    "climate_dictionary = climate_dictionary.drop_duplicates(\n",
    "    subset='term', keep='first')\n",
    "\n",
    "climate_dictionary.to_csv(\n",
    "    dist_path + 'raw_climate_dictionary.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
