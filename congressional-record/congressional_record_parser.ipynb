{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "DATA_PATH = \"data/\"\n",
    "DIST_PATH = \"dist/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert speeches in each Congress into a CSV with added metadata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert hein-daily `.txt` files to a dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_hein_txt_to_df(input_file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(input_file_path, sep='|',\n",
    "                         encoding='ISO-8859-1', on_bad_lines='skip')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error reading the file:\", e)\n",
    "        return None\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataframe of file paths for all Congresses and their metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "directories = ['speeches', 'speaker-maps', 'descriptions']\n",
    "file_paths_dict = {dir_name: {} for dir_name in directories}\n",
    "\n",
    "for dir_name in directories:\n",
    "    for filename in os.listdir(DATA_PATH + dir_name):\n",
    "        # Extract the Congress number from the filename\n",
    "        congress_number = re.search(r'\\d+', filename).group()\n",
    "        file_paths_dict[dir_name][congress_number] = filename\n",
    "\n",
    "file_paths_df = pd.DataFrame(file_paths_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataframe for each Congress and save to disk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [01:27,  4.86s/it]\n"
     ]
    }
   ],
   "source": [
    "individual_congresses_path = DIST_PATH + \"individual_congresses/\"\n",
    "\n",
    "if not os.path.exists(individual_congresses_path):\n",
    "    os.makedirs(individual_congresses_path)\n",
    "\n",
    "for index, row in tqdm(file_paths_df.iterrows()):\n",
    "    speeches_df = convert_hein_txt_to_df(\n",
    "        DATA_PATH + \"speeches/\" + row['speeches'])\n",
    "\n",
    "    speaker_maps_df = convert_hein_txt_to_df(\n",
    "        DATA_PATH + \"speaker-maps/\" + row['speaker-maps'])\n",
    "    speaker_maps_df = speaker_maps_df.rename(\n",
    "        columns={'speakerid': 'speaker_id',\n",
    "                 'lastname': 'last_name',\n",
    "                 'firstname': 'first_name',\n",
    "                 'nonvoting': 'non_voting'})\n",
    "\n",
    "    descriptions_df = convert_hein_txt_to_df(\n",
    "        DATA_PATH + \"descriptions/\" + row['descriptions'])\n",
    "    descriptions_df = descriptions_df.drop(\n",
    "        ['first_name', 'last_name', 'state', 'gender', 'chamber'], axis=1)  # Drop redundant columns\n",
    "\n",
    "    congress_df = speeches_df.merge(\n",
    "        speaker_maps_df, on='speech_id', how='left')\n",
    "    congress_df = congress_df.merge(\n",
    "        descriptions_df, on='speech_id', how='left')\n",
    "\n",
    "    congress_file_name = \"congress_\" + \\\n",
    "        row['speeches'].split('.')[0].split('_')[1] + \".csv\"\n",
    "\n",
    "    congress_df.to_csv(individual_congresses_path +\n",
    "                       congress_file_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a combined dataframe for the entire Congressional Record\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_congresses_path = DIST_PATH + \"individual_congresses/\"\n",
    "\n",
    "file_paths = [individual_congresses_path +\n",
    "              file_name for file_name in os.listdir(individual_congresses_path)]\n",
    "\n",
    "congressional_record_df = pd.concat(\n",
    "    [\n",
    "        pd.read_csv(file_path).assign(\n",
    "            congress=file_path.split('/')[-1].split('_')[-1].split('.')[0]\n",
    "        )\n",
    "        for file_path in file_paths\n",
    "    ]\n",
    ")\n",
    "\n",
    "congressional_record_df.to_csv(\n",
    "    DIST_PATH + \"congressional_record.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
